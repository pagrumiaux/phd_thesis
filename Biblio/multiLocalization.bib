
@techreport{habets_room_2006,
	title = {Room impulse response generator},
	institution = {Technische Universiteit Eindhoven},
	author = {Habets, Emanuel A. P.},
	year = {2006},
	file = {rir_generator.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\U6W3GTW5\\rir_generator.pdf:application/pdf},
}

@article{kitic_tramp:_2018,
	title = {{TRAMP}: {TRacking} by a realtime {AMbisonic}-based {Particle} filter},
	abstract = {This article presents a multiple sound source localization and tracking system, fed by the Eigenmike array. The First Order Ambisonics (FOA) format is used to build a pseudointensity-based spherical histogram, from which the source position estimates are deduced. These instantaneous estimates are processed by a well-known tracking system relying on a set of particle ﬁlters. While the novelty within localization and tracking is incremental, the fully-functional, complete and real-time running system based on these algorithms is proposed for the ﬁrst time. As such, it could serve as an additional baseline method of the LOCATA challenge.},
	language = {en},
	journal = {LOCATA Challenge Workshop},
	author = {Kitic, Srdan and Guérin, Alexandre},
	year = {2018},
	keywords = {lu},
	file = {Guérin - 2018 - Orange Labs 4 Rue du Clos Courtel 35510 Cesson-Sév.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\V85SDXXK\\Guérin - 2018 - Orange Labs 4 Rue du Clos Courtel 35510 Cesson-Sév.pdf:application/pdf},
}

@book{chollet_deep_2017,
	title = {Deep learning with {Python}},
	isbn = {978-1-61729-443-3},
	language = {en},
	publisher = {Simon and Schuster},
	author = {Chollet, François},
	year = {2017},
	keywords = {lu, Machine learning, Neural networks (Computer science), Python (Computer program language)},
	file = {Chollet - 2018 - Deep learning with Python.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\S8KTC9RZ\\Chollet - 2018 - Deep learning with Python.pdf:application/pdf},
}

@phdthesis{perotin_localisation_2019,
	title = {Localisation et rehaussement de sources de parole au format {Ambisonique}},
	language = {French},
	school = {Université de Lorraine},
	author = {Perotin, Lauréline},
	month = oct,
	year = {2019},
	keywords = {partiel-lu},
	file = {Perotin - 2019 - Localisation et rehaussement de sources de parole .pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\DH3UF3GL\\Perotin - 2019 - Localisation et rehaussement de sources de parole .pdf:application/pdf},
}

@inproceedings{perotin_crnn-based_2018,
	title = {{CRNN}-based joint azimuth and elevation localization with the {Ambisonics} intensity vector},
	doi = {10.1109/IWAENC.2018.8521403},
	abstract = {We present a source localization system for first-order Ambisonics (FOA) contents based on a stacked convolutional and recurrent neural network (CRNN). We propose to use as input to the CRNN the FOA acoustic intensity vector, which is easy to compute and closely linked to the sound direction of arrival (DoA). The system estimates the DoA of a point source in both azimuth and elevation. We conduct an experimental evaluation in configurations including reverberation, noise, and various speaker w. r. t. microphone orientations. The results show that the proposed architecture and input allow the network to return accurate location estimates in realistic conditions compared to another recent CRNN-based system.},
	booktitle = {International {Workshop} on {Acoustic} {Signal} {Enhancement}},
	author = {Perotin, Lauréline and Serizel, Romain and Vincent, Emmanuel and Guérin, Alexandre},
	month = sep,
	year = {2018},
	keywords = {lu},
	pages = {241--245},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\RQML4978\\Zotero\\storage\\24EP5U5G\\8521403.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\JBSR8ZXL\\Perotin et al. - 2018 - CRNN-based Joint Azimuth and Elevation Localizatio.pdf:application/pdf},
}

@book{zotter_ambisonics_2019,
	title = {Ambisonics: a practical {3D} audio theory for recording, studio production, sound reinforcement, and virtual reality},
	isbn = {978-3-030-17206-0 978-3-030-17207-7},
	shorttitle = {Ambisonics},
	language = {en},
	urldate = {2020-05-02},
	publisher = {Springer Nature},
	author = {Zotter, Franz and Frank, Matthias},
	year = {2019},
	keywords = {non-lu},
	file = {Zotter et Frank - 2019 - Ambisonics A Practical 3D Audio Theory for Record.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\8EBYJ9NF\\Zotter et Frank - 2019 - Ambisonics A Practical 3D Audio Theory for Record.pdf:application/pdf},
}

@article{perotin_crnn-based_2019,
	title = {{CRNN}-based multiple {DoA} estimation using acoustic intensity features for {Ambisonics} recordings},
	volume = {13},
	issn = {1941-0484},
	doi = {10.1109/JSTSP.2019.2900164},
	abstract = {Localizing audio sources is challenging in real reverberant environments, especially when several sources are active. We propose to use a neural network built from stacked convolutional and recurrent layers in order to estimate the directions of arrival of multiple sources from a first-order Ambisonics recording. It returns the directions of arrival over a discrete grid of a known number of sources. We propose to use features derived from the acoustic intensity vector as inputs. We analyze the behavior of the neural network by means of a visualization technique called layerwise relevance propagation. This analysis highlights which parts of the input signal are relevant in a given situation. We also conduct experiments to evaluate the performance of our system in various environments, from simulated rooms to real recordings, with one or two speech sources. The results show that the proposed features significantly improve performances with respect to raw Ambisonics inputs.},
	number = {1},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Perotin, Lauréline and Serizel, Romain and Vincent, Emmanuel and Guérin, Alexandre},
	month = mar,
	year = {2019},
	keywords = {lu},
	pages = {22--33},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\RQML4978\\Zotero\\storage\\IFFJIMX5\\8643769.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\9RS53UMH\\Perotin et al. - 2019 - CRNN-Based Multiple DoA Estimation Using Acoustic .pdf:application/pdf;Perotin - CRNN-based multiple DoA estimation using Ambisonic.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\TPWGMJPJ\\Perotin - CRNN-based multiple DoA estimation using Ambisonic.pdf:application/pdf},
}

@techreport{garofolo_timit_1993,
	title = {{TIMIT} acoustic-phonetic continuous speech corpus},
	abstract = {The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance. Corpus design was a joint effort among the Massachusetts Institute of Technology (MIT), SRI International (SRI) and Texas Instruments, Inc. (TI). The speech was recorded at TI, transcribed at MIT and verified and prepared for CD-ROM production by the National Institute of Standards and Technology (NIST).},
	author = {Garofolo, John S. and Lamel, Lori F. and Fisher, William M. and Fiscus, Jonathan G. and Pallett, David S. and Dahlgren, Nancy L. and Zue, Victor},
	year = {1993},
}

@article{allen_image_1979,
	title = {Image method for efficiently simulating small‐room acoustics},
	volume = {65},
	issn = {0001-4966},
	doi = {10.1121/1.382599},
	language = {en},
	number = {4},
	urldate = {2021-03-18},
	journal = {The Journal of the Acoustical Society of America},
	author = {Allen, Jont B. and Berkley, David A.},
	year = {1979},
	pages = {943--950},
	file = {Allen et Berkley - 1979 - Image method for efficiently simulating small‐room.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\AIKAPSD5\\Allen et Berkley - 1979 - Image method for efficiently simulating small‐room.pdf:application/pdf},
}

@article{dozat_incorporating_2016,
	title = {Incorporating {Nesterov} momentum into {Adam}},
	abstract = {Semantic Scholar extracted view of \&quot;Incorporating Nesterov Momentum into Adam\&quot; by Timothy Dozat},
	language = {en},
	urldate = {2021-03-19},
	journal = {ICLR 2016},
	author = {Dozat, Timothy},
	year = {2016},
	file = {Snapshot:C\:\\Users\\RQML4978\\Zotero\\storage\\CKNGVI2M\\d44efdc542f2cc5e196f04bc76bc783bfd7084af.html:text/html},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is all you need},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	language = {en},
	booktitle = {Conference on {Neural} {Information} {Processing} {System}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	keywords = {lu},
	pages = {5998--6008},
	file = {Vaswani et al. - 2017 - Attention Is All You Need.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\FZV3RM7K\\Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf},
}

@article{evers_locata_2020,
	title = {The {LOCATA} {Challenge}: acoustic source localization and tracking},
	volume = {28},
	issn = {2329-9304},
	shorttitle = {The {LOCATA} {Challenge}},
	doi = {10.1109/TASLP.2020.2990485},
	abstract = {The ability to localize and track acoustic events is a fundamental prerequisite for equipping machines with the ability to be aware of and engage with humans in their surrounding environment. However, in realistic scenarios, audio signals are adversely affected by reverberation, noise, interference, and periods of speech inactivity. In dynamic scenarios, where the sources and microphone platforms may be moving, the signals are additionally affected by variations in the source-sensor geometries. In practice, approaches to sound source localization and tracking are often impeded by missing estimates of active sources, estimation errors, as well as false estimates. The aim of the LOCAlization and TrAcking (LOCATA) Challenge is an open-access framework for the objective evaluation and benchmarking of broad classes of algorithms for sound source localization and tracking. This article provides a review of relevant localization and tracking algorithms and, within the context of the existing literature, a detailed evaluation and dissemination of the LOCATA submissions. The evaluation highlights achievements in the field, open challenges, and identifies potential future directions.},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Evers, Christine and Löllmann, Heinrich W. and Mellmann, Heinrich and Schmidt, Alexander and Barfuss, Hendrik and Naylor, Patrick A. and Kellermann, Walter},
	year = {2020},
	pages = {1620--1643},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\RQML4978\\Zotero\\storage\\GLJS5TLJ\\9079214.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\F8QY57WK\\Evers et al. - 2020 - The LOCATA Challenge Acoustic Source Localization.pdf:application/pdf},
}

@article{bach_pixel-wise_2015,
	title = {On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
	volume = {10},
	doi = {10.1371/journal.pone.0130140},
	abstract = {This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers by introducing a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
	number = {7},
	journal = {PloS one},
	author = {Bach, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
	year = {2015},
	file = {Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\IQVU3WWQ\\Bach et al. - 2015 - On Pixel-Wise Explanations for Non-Linear Classifi.pdf:application/pdf},
}

@article{kuhn_hungarian_1955,
	title = {The {Hungarian} method for the assignment problem},
	volume = {2},
	issn = {00281441, 19319193},
	doi = {10.1002/nav.3800020109},
	language = {en},
	number = {1-2},
	urldate = {2021-10-08},
	journal = {Naval Research Logistics Quarterly},
	author = {Kuhn, Harold W.},
	month = mar,
	year = {1955},
	pages = {83--97},
	file = {Kuhn - 1955 - The Hungarian method for the assignment problem.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\VZS6A3E4\\Kuhn - 1955 - The Hungarian method for the assignment problem.pdf:application/pdf},
}
