
@techreport{garofolo_timit_1993,
	title = {{TIMIT} acoustic-phonetic continuous speech corpus},
	abstract = {The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance. Corpus design was a joint effort among the Massachusetts Institute of Technology (MIT), SRI International (SRI) and Texas Instruments, Inc. (TI). The speech was recorded at TI, transcribed at MIT and verified and prepared for CD-ROM production by the National Institute of Standards and Technology (NIST).},
	author = {Garofolo, John S. and Lamel, Lori F. and Fisher, William M. and Fiscus, Jonathan G. and Pallett, David S. and Dahlgren, Nancy L. and Zue, Victor},
	year = {1993},
}

@article{dozat_incorporating_2016,
	title = {Incorporating {Nesterov} momentum into {Adam}},
	abstract = {Semantic Scholar extracted view of \&quot;Incorporating Nesterov Momentum into Adam\&quot; by Timothy Dozat},
	language = {en},
	urldate = {2021-03-19},
	journal = {ICLR 2016},
	author = {Dozat, Timothy},
	year = {2016},
	file = {Snapshot:C\:\\Users\\RQML4978\\Zotero\\storage\\CKNGVI2M\\d44efdc542f2cc5e196f04bc76bc783bfd7084af.html:text/html},
}

@article{evers_locata_2020,
	title = {The {LOCATA} {Challenge}: acoustic source localization and tracking},
	volume = {28},
	issn = {2329-9304},
	shorttitle = {The {LOCATA} {Challenge}},
	doi = {10.1109/TASLP.2020.2990485},
	abstract = {The ability to localize and track acoustic events is a fundamental prerequisite for equipping machines with the ability to be aware of and engage with humans in their surrounding environment. However, in realistic scenarios, audio signals are adversely affected by reverberation, noise, interference, and periods of speech inactivity. In dynamic scenarios, where the sources and microphone platforms may be moving, the signals are additionally affected by variations in the source-sensor geometries. In practice, approaches to sound source localization and tracking are often impeded by missing estimates of active sources, estimation errors, as well as false estimates. The aim of the LOCAlization and TrAcking (LOCATA) Challenge is an open-access framework for the objective evaluation and benchmarking of broad classes of algorithms for sound source localization and tracking. This article provides a review of relevant localization and tracking algorithms and, within the context of the existing literature, a detailed evaluation and dissemination of the LOCATA submissions. The evaluation highlights achievements in the field, open challenges, and identifies potential future directions.},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Evers, Christine and Löllmann, Heinrich W. and Mellmann, Heinrich and Schmidt, Alexander and Barfuss, Hendrik and Naylor, Patrick A. and Kellermann, Walter},
	year = {2020},
	pages = {1620--1643},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\RQML4978\\Zotero\\storage\\GLJS5TLJ\\9079214.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\F8QY57WK\\Evers et al. - 2020 - The LOCATA Challenge Acoustic Source Localization.pdf:application/pdf},
}

@article{kuhn_hungarian_1955,
	title = {The {Hungarian} method for the assignment problem},
	volume = {2},
	issn = {00281441, 19319193},
	doi = {10.1002/nav.3800020109},
	language = {en},
	number = {1-2},
	urldate = {2021-10-08},
	journal = {Naval Research Logistics Quarterly},
	author = {Kuhn, Harold W.},
	month = mar,
	year = {1955},
	pages = {83--97},
	file = {Kuhn - 1955 - The Hungarian method for the assignment problem.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\VZS6A3E4\\Kuhn - 1955 - The Hungarian method for the assignment problem.pdf:application/pdf},
}

@inproceedings{vogl_drum_2017,
	title = {Drum transcription via joint beat and drum modeling using convolutional recurrent neural networks},
	abstract = {Existing systems for automatic transcription of drum tracks from polyphonic music focus on detecting drum instrument onsets but lack consideration of additional meta information like bar boundaries, tempo, and meter. We address this limitation by proposing a system which has the capability to detect drum instrument onsets along with the corresponding beats and downbeats. In this design, the system has the means to utilize information on the rhythmical structure of a song which is closely related to the desired drum transcript. To this end, we introduce and compare different architectures for this task, i.e., recurrent, convolutional, and recurrent-convolutional neural networks. We evaluate our systems on two well-known data sets and an additional new data set containing both drum and beat annotations. We show that convolutional and recurrentconvolutional neural networks perform better than state-ofthe-art methods and that learning beats jointly with drums can be beneﬁcial for the task of drum detection.},
	language = {en},
	booktitle = {Conference of the {International} {Society} for {Music} {Information} {Retrieval}},
	author = {Vogl, Richard and Dorfer, Matthias and Widmer, Gerhard and Knees, Peter},
	year = {2017},
	pages = {150--157},
	file = {Vogl et al. - 2017 - DRUM TRANSCRIPTION VIA JOINT BEAT AND DRUM MODELIN.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\ST8ID7V9\\Vogl et al. - 2017 - DRUM TRANSCRIPTION VIA JOINT BEAT AND DRUM MODELIN.pdf:application/pdf},
}
