
@article{kingma_adam:_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for ﬁrst-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efﬁcient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the inﬁnity norm.},
	language = {en},
	urldate = {2019-04-11},
	journal = {arXiv:1412.6980},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2014},
	keywords = {Computer Science - Machine Learning},
	file = {Kingma et Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\AM7Q3XPX\\Kingma et Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf},
}

@article{stoter_countnet:_2019,
	title = {{CountNet}: estimating the number of concurrent speakers using supervised learning},
	volume = {27},
	issn = {2329-9290, 2329-9304},
	shorttitle = {{CountNet}},
	doi = {10.1109/TASLP.2018.2877892},
	abstract = {Estimating the maximum number of concurrent speakers from single-channel mixtures is a challenging problem and an essential ﬁrst step to address various audio-based tasks such as blind source separation, speaker diarization, and audio surveillance. We propose a unifying probabilistic paradigm, where deep neural network architectures are used to infer output posterior distributions. These probabilities are in turn processed to yield discrete point estimates. Designing such architectures often involves two important and complementary aspects that we investigate and discuss. First, we study how recent advances in deep architectures may be exploited for the task of speaker count estimation. In particular, we show that convolutional recurrent neural networks outperform recurrent networks used in a previous study when adequate input features are used. Even for short segments of speech mixtures, we can estimate up to ﬁve speakers, with a signiﬁcantly lower error than other methods. Second, through comprehensive evaluation, we compare the best-performing method to several baselines, as well as the inﬂuence of gain variations, different data sets, and reverberation. The output of our proposed method is compared to human performance. Finally, we give insights into the strategy used by our proposed method.},
	language = {en},
	number = {2},
	urldate = {2019-01-15},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Stöter, Fabian-Robert and Chakrabarty, Soumitro and Edler, Bernd and Habets, Emanuel A. P.},
	year = {2019},
	keywords = {lu},
	pages = {268--282},
	file = {Stoter et al. - 2019 - CountNet Estimating the Number of Concurrent Spea.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\AZLNM27I\\Stoter et al. - 2019 - CountNet Estimating the Number of Concurrent Spea.pdf:application/pdf},
}

@techreport{habets_room_2006,
	title = {Room impulse response generator},
	institution = {Technische Universiteit Eindhoven},
	author = {Habets, Emanuel A. P.},
	year = {2006},
	file = {rir_generator.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\U6W3GTW5\\rir_generator.pdf:application/pdf},
}

@inproceedings{larnel_bref_1991,
	title = {{BREF}, a large vocabulary spoken corpus for {French}},
	abstract = {This paper presents some of the design considerations of BREF, a large read-speech corpus for French. BREF was designed to provide continuous speech data for the development of dictation machines, for the evaluation of continuous speech recognition systems (both speaker-dependent and speakerindependent), and for the study of phonological variations. The texts to be read were selected from 5 million words of the French newspaper, Le Monde. In total, 11,000 texts were selected, with selection criteria that emphasisized maximizing the number of distinct triphones. Separate text materials were selected for training and test corpora. Ninety speakers have been recorded, each providing between 5,000 and 10,000 words (approximately 40-70 min.) of speech.},
	booktitle = {Eurospeech},
	author = {Larnel, Lori F. and Gauvain, Jean-Luc and Eskénazi, Maxine},
	year = {1991},
	keywords = {Expect, Selection (user interface), Speech corpus, Speech recognition, Text corpus, Time-compressed speech, Triphone, Vocabulary},
	file = {Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\2NKUZWBU\\Larnel et al. - 1991 - BREF, a large vocabulary spoken corpus for French.pdf:application/pdf},
}

@inproceedings{stoter_classification_2018,
	title = {Classification vs. regression in supervised learning for single channel speaker count estimation},
	doi = {10.1109/ICASSP.2018.8462159},
	abstract = {The task of estimating the maximum number of concurrent speakers from single channel mixtures is important for various audio-based applications, such as blind source separation, speaker diarisation, audio surveillance or auditory scene classification. Building upon powerful machine learning methodology, we develop a Deep Neural Network (DNN) that estimates a speaker count. While DNNs efficiently map input representations to output targets, it remains unclear how to best handle the network output to infer integer source count estimates, as a discrete count estimate can either be tackled as a regression or a classification problem. In this paper, we investigate this important design decision and also address complementary parameter choices such as the input representation. We evaluate a state-of-the-art DNN audio model based on a Bi-directional Long Short-Term Memory network architecture for speaker count estimations. Through experimental evaluations aimed at identifying the best overall strategy for the task and show results for five seconds speech segments in mixtures of up to ten speakers.},
	booktitle = {{IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Stöter, Fabien-Robert and Chakrabarty, Soumitro and Edler, Bernd and Habets, Emanuel A. P.},
	year = {2018},
	keywords = {acoustic signal processing, audio based applications, audio signal processing, audio surveillance, auditory scene classification, bidirectional long short term memory network architecture, blind source separation, channel estimation, Channel estimation, classification problem, cocktail-party, Computer architecture, concurrent speakers, deep neural network, design decision, discrete count estimate, DNN audio model, Estimation, integer source count estimates, learning (artificial intelligence), lu, Machine learning, map input representations, maximum number, network output, neural nets, Neural networks, number of concurrent speakers, output targets, overlapped speech, pattern classification, powerful machine learning methodology, regression analysis, regression problem, single channel mixtures, single channel speaker count estimation, speaker count estimation, speaker diarisation, speaker recognition, speech segments, supervised learning, Task analysis, Training},
	pages = {436--440},
	file = {arXiv Fulltext PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\4BL2RGGJ\\Stöter et al. - 2018 - Classification vs. Regression in Supervised Learni.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\RQML4978\\Zotero\\storage\\E2NLA3V7\\1712.html:text/html},
}

@phdthesis{perotin_localisation_2019,
	title = {Localisation et rehaussement de sources de parole au format {Ambisonique}},
	language = {French},
	school = {Université de Lorraine},
	author = {Perotin, Lauréline},
	month = oct,
	year = {2019},
	keywords = {partiel-lu},
	file = {Perotin - 2019 - Localisation et rehaussement de sources de parole .pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\DH3UF3GL\\Perotin - 2019 - Localisation et rehaussement de sources de parole .pdf:application/pdf},
}

@article{perotin_crnn-based_2019,
	title = {{CRNN}-based multiple {DoA} estimation using acoustic intensity features for {Ambisonics} recordings},
	volume = {13},
	issn = {1941-0484},
	doi = {10.1109/JSTSP.2019.2900164},
	abstract = {Localizing audio sources is challenging in real reverberant environments, especially when several sources are active. We propose to use a neural network built from stacked convolutional and recurrent layers in order to estimate the directions of arrival of multiple sources from a first-order Ambisonics recording. It returns the directions of arrival over a discrete grid of a known number of sources. We propose to use features derived from the acoustic intensity vector as inputs. We analyze the behavior of the neural network by means of a visualization technique called layerwise relevance propagation. This analysis highlights which parts of the input signal are relevant in a given situation. We also conduct experiments to evaluate the performance of our system in various environments, from simulated rooms to real recordings, with one or two speech sources. The results show that the proposed features significantly improve performances with respect to raw Ambisonics inputs.},
	number = {1},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Perotin, Lauréline and Serizel, Romain and Vincent, Emmanuel and Guérin, Alexandre},
	month = mar,
	year = {2019},
	keywords = {lu},
	pages = {22--33},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\RQML4978\\Zotero\\storage\\IFFJIMX5\\8643769.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\9RS53UMH\\Perotin et al. - 2019 - CRNN-Based Multiple DoA Estimation Using Acoustic .pdf:application/pdf;Perotin - CRNN-based multiple DoA estimation using Ambisonic.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\TPWGMJPJ\\Perotin - CRNN-based multiple DoA estimation using Ambisonic.pdf:application/pdf},
}

@techreport{garofolo_timit_1993,
	title = {{TIMIT} acoustic-phonetic continuous speech corpus},
	abstract = {The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance. Corpus design was a joint effort among the Massachusetts Institute of Technology (MIT), SRI International (SRI) and Texas Instruments, Inc. (TI). The speech was recorded at TI, transcribed at MIT and verified and prepared for CD-ROM production by the National Institute of Standards and Technology (NIST).},
	author = {Garofolo, John S. and Lamel, Lori F. and Fisher, William M. and Fiscus, Jonathan G. and Pallett, David S. and Dahlgren, Nancy L. and Zue, Victor},
	year = {1993},
}

@article{allen_image_1979,
	title = {Image method for efficiently simulating small‐room acoustics},
	volume = {65},
	issn = {0001-4966},
	doi = {10.1121/1.382599},
	language = {en},
	number = {4},
	urldate = {2021-03-18},
	journal = {The Journal of the Acoustical Society of America},
	author = {Allen, Jont B. and Berkley, David A.},
	year = {1979},
	pages = {943--950},
	file = {Allen et Berkley - 1979 - Image method for efficiently simulating small‐room.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\AIKAPSD5\\Allen et Berkley - 1979 - Image method for efficiently simulating small‐room.pdf:application/pdf},
}
