
@techreport{habets_room_2006,
	title = {Room impulse response generator},
	institution = {Technische Universiteit Eindhoven},
	author = {Habets, Emanuel A. P.},
	year = {2006},
	file = {rir_generator.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\U6W3GTW5\\rir_generator.pdf:application/pdf},
}

@article{oord_wavenet:_2016,
	title = {{WaveNet}: a generative model for raw audio},
	abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efﬁciently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-ofthe-art performance, with human listeners rating it as signiﬁcantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal ﬁdelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we ﬁnd that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
	language = {en},
	journal = {arXiv:1609.03499},
	author = {Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	month = sep,
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound, lu},
	file = {Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\Z8FP47L6\\Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf:application/pdf},
}

@inproceedings{perotin_crnn-based_2018,
	title = {{CRNN}-based joint azimuth and elevation localization with the {Ambisonics} intensity vector},
	doi = {10.1109/IWAENC.2018.8521403},
	abstract = {We present a source localization system for first-order Ambisonics (FOA) contents based on a stacked convolutional and recurrent neural network (CRNN). We propose to use as input to the CRNN the FOA acoustic intensity vector, which is easy to compute and closely linked to the sound direction of arrival (DoA). The system estimates the DoA of a point source in both azimuth and elevation. We conduct an experimental evaluation in configurations including reverberation, noise, and various speaker w. r. t. microphone orientations. The results show that the proposed architecture and input allow the network to return accurate location estimates in realistic conditions compared to another recent CRNN-based system.},
	booktitle = {International {Workshop} on {Acoustic} {Signal} {Enhancement}},
	author = {Perotin, Lauréline and Serizel, Romain and Vincent, Emmanuel and Guérin, Alexandre},
	month = sep,
	year = {2018},
	keywords = {lu},
	pages = {241--245},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\RQML4978\\Zotero\\storage\\24EP5U5G\\8521403.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\RQML4978\\Zotero\\storage\\JBSR8ZXL\\Perotin et al. - 2018 - CRNN-based Joint Azimuth and Elevation Localizatio.pdf:application/pdf},
}

@article{cohen_relative_2004,
	title = {Relative transfer function identification using speech signals},
	volume = {12},
	issn = {1558-2353},
	doi = {10.1109/TSA.2004.832975},
	abstract = {An important component of a multichannel hands-free communication system is the identification of the relative transfer function between sensors in response to a desired source signal. In this paper, a robust system identification approach adapted to speech signals is proposed. A weighted least-squares optimization criterion is introduced, which considers the uncertainty of the desired signal presence in the observed signals. An asymptotically unbiased estimate for the system's transfer function is derived, and a corresponding recursive online implementation is presented. We show that compared to a competing nonstationarity-based method, a smaller error variance is achieved and generally shorter observation intervals are required. Furthermore, in the case of a time-varying system, faster convergence and higher reliability of the system identification are obtained by using the proposed method than by using the nonstationarity-based method. Evaluation of the proposed system identification approach is performed under various noise conditions, including simulated stationary and nonstationary white Gaussian noise, and car interior noise in real pseudo-stationary and nonstationary environments. The experimental results confirm the advantages of proposed approach.},
	number = {5},
	journal = {IEEE Transactions on Speech and Audio Processing},
	author = {Cohen, Israel},
	month = sep,
	year = {2004},
	keywords = {lu},
	pages = {451--459},
	file = {Cohen - 2004 - Relative transfer function identification using sp.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\TA6NM6ZQ\\Cohen - 2004 - Relative transfer function identification using sp.pdf:application/pdf},
}

@article{shalvi_system_1996,
	title = {System identification using nonstationary signals},
	volume = {44},
	issn = {1941-0476},
	doi = {10.1109/78.533725},
	abstract = {The conventional method for identifying the transfer function of an unknown linear system consists of a least squares fit of its input to its output. It is equivalent to identifying the frequency response of the system by calculating the empirical cross-spectrum between the system's input and output, divided by the empirical auto-spectrum of the input process. However, if the additive noise at the system's output is correlated with the input process, e.g., in case of environmental noise that affects both system's input and output, the method may suffer from a severe bias effect. We present a modification of the cross-spectral method that exploits nonstationary features in the data in order to circumvent bias effects caused by correlated stationary noise. The proposed method is particularly attractive to problems of multichannel signal enhancement and noise cancellation, when the desired signal is nonstationary in nature, e.g., speech or image.},
	number = {8},
	journal = {IEEE Transactions on Signal Processing},
	author = {Shalvi, Ofir and Weinstein, Ehud},
	month = aug,
	year = {1996},
	pages = {2055--2063},
	file = {Shalvi et Weinstein - 1996 - System identification using nonstationary signals.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\IKYG2JS6\\Shalvi et Weinstein - 1996 - System identification using nonstationary signals.pdf:application/pdf},
}

@inproceedings{daniel_time_2020,
	title = {Time domain velocity vector for retracing the multipath propagation},
	isbn = {978-1-5090-6631-5},
	doi = {10.1109/ICASSP40776.2020.9054561},
	abstract = {We propose a conceptually and computationally simple form of sound velocity that offers a readable view of the interference between direct and indirect sound waves. Unlike most approaches in the literature, it jointly exploits both active and reactive sound intensity measurements, as typically derived from a ﬁrst order ambisonics recording. This representation has a potential both as a valuable tool for directly analyzing sound multipath propagation, as well as being a new spatial feature format for machine learning algorithms in audio and acoustics. As a showcase, we demonstrate that the Directionof-Arrival and the range of a sound source can be estimated as a development of this approach. To the best knowledge of the authors, this is the ﬁrst time that range is estimated from an ambisonics recording.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {{IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Daniel, Jerome and Kitic, Srdan},
	year = {2020},
	keywords = {lu},
	pages = {421--425},
	file = {Daniel et Kitic - 2020 - Time Domain Velocity Vector for Retracing the Mult.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\7RWFEP3N\\Daniel et Kitic - 2020 - Time Domain Velocity Vector for Retracing the Mult.pdf:application/pdf},
}

@article{gannot_signal_2001,
	title = {Signal enhancement using beamforming and nonstationarity with applications to speech},
	volume = {49},
	issn = {1941-0476},
	doi = {10.1109/78.934132},
	abstract = {We consider a sensor array located in an enclosure, where arbitrary transfer functions (TFs) relate the source signal and the sensors. The array is used for enhancing a signal contaminated by interference. Constrained minimum power adaptive beamforming, which has been suggested by Frost (1972) and, in particular, the generalized sidelobe canceler (GSC) version, which has been developed by Griffiths and Jim (1982), are the most widely used beamforming techniques. These methods rely on the assumption that the received signals are simple delayed versions of the source signal. The good interference suppression attained under this assumption is severely impaired in complicated acoustic environments, where arbitrary TFs may be encountered. In this paper, we consider the arbitrary TF case. We propose a GSC solution, which is adapted to the general TF case. We derive a suboptimal algorithm that can be implemented by estimating the TFs ratios, instead of estimating the TFs. The TF ratios are estimated by exploiting the nonstationarity characteristics of the desired signal. The algorithm is applied to the problem of speech enhancement in a reverberating room. The discussion is supported by an experimental study using speech and noise signals recorded in an actual room acoustics environment.},
	number = {8},
	journal = {IEEE Transactions on Signal Processing},
	author = {Gannot, Sharon and Burshtein, David and Weinstein, Ehud},
	month = aug,
	year = {2001},
	pages = {1614--1626},
	file = {gannot2001.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\QDZ29X4E\\gannot2001.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\RQML4978\\Zotero\\storage\\E7MV6WSX\\references.html:text/html;Version soumise:C\:\\Users\\RQML4978\\Zotero\\storage\\8S8AXFEY\\Gannot et al. - 2001 - Signal enhancement using beamforming and nonstatio.pdf:application/pdf},
}

@techreport{garofolo_timit_1993,
	title = {{TIMIT} acoustic-phonetic continuous speech corpus},
	abstract = {The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance. Corpus design was a joint effort among the Massachusetts Institute of Technology (MIT), SRI International (SRI) and Texas Instruments, Inc. (TI). The speech was recorded at TI, transcribed at MIT and verified and prepared for CD-ROM production by the National Institute of Standards and Technology (NIST).},
	author = {Garofolo, John S. and Lamel, Lori F. and Fisher, William M. and Fiscus, Jonathan G. and Pallett, David S. and Dahlgren, Nancy L. and Zue, Victor},
	year = {1993},
}

@article{allen_image_1979,
	title = {Image method for efficiently simulating small‐room acoustics},
	volume = {65},
	issn = {0001-4966},
	doi = {10.1121/1.382599},
	language = {en},
	number = {4},
	urldate = {2021-03-18},
	journal = {The Journal of the Acoustical Society of America},
	author = {Allen, Jont B. and Berkley, David A.},
	year = {1979},
	pages = {943--950},
	file = {Allen et Berkley - 1979 - Image method for efficiently simulating small‐room.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\AIKAPSD5\\Allen et Berkley - 1979 - Image method for efficiently simulating small‐room.pdf:application/pdf},
}

@article{dozat_incorporating_2016,
	title = {Incorporating {Nesterov} momentum into {Adam}},
	abstract = {Semantic Scholar extracted view of \&quot;Incorporating Nesterov Momentum into Adam\&quot; by Timothy Dozat},
	language = {en},
	urldate = {2021-03-19},
	journal = {ICLR 2016},
	author = {Dozat, Timothy},
	year = {2016},
	file = {Snapshot:C\:\\Users\\RQML4978\\Zotero\\storage\\CKNGVI2M\\d44efdc542f2cc5e196f04bc76bc783bfd7084af.html:text/html},
}

@inproceedings{katharopoulos_transformers_2020,
	title = {Transformers are {RNNs}:  fast autoregressive transformers with linear attention},
	abstract = {Transformers achieve remarkable performance in several tasks but due to their quadratic complexity, with respect to the input’s length, they are prohibitively slow for very long sequences. To address this limitation, we express the self-attention as a linear dot-product of kernel feature maps and make use of the associativity property of matrix products to reduce the complexity from O N 2 to O (N ), where N is the sequence length. We show that this formulation permits an iterative implementation that dramatically accelerates autoregressive transformers and reveals their relationship to recurrent neural networks. Our linear transformers achieve similar performance to vanilla transformers and they are up to 4000x faster on autoregressive prediction of very long sequences.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, François},
	year = {2020},
	pages = {5156--5165},
	file = {Katharopoulos et al. - Transformers are RNNs  Fast Autoregressive Transf.pdf:C\:\\Users\\RQML4978\\Zotero\\storage\\E42SB2UQ\\Katharopoulos et al. - Transformers are RNNs  Fast Autoregressive Transf.pdf:application/pdf},
}
